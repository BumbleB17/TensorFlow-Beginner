{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. Callbacks.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aye-Nyein-Thaw/TensorFlow-Beginner/blob/main/coding-exercise/week%205/part1/1_Callbacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4PeVggwTws3"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhHJcvK8QV4Y"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B81O_LFTws9"
      },
      "source": [
        "## Load diabetes dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Df0hPiCVTws-",
        "outputId": "2cedffe9-b31e-417c-8f57-5a4d1cf74206"
      },
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "diabetes_dataset = load_diabetes()\n",
        "print(diabetes_dataset['DESCR'])\n",
        "\n",
        "data = diabetes_dataset['data']\n",
        "targets = diabetes_dataset['target']\n",
        "\n",
        "# Normalise the target data (this will make clearer training curves)\n",
        "targets = (targets - targets.mean(axis = 0)) / targets.std()\n",
        "\n",
        "# Split the data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, targets, test_size = 0.1)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _diabetes_dataset:\n",
            "\n",
            "Diabetes dataset\n",
            "----------------\n",
            "\n",
            "Ten baseline variables, age, sex, body mass index, average blood\n",
            "pressure, and six blood serum measurements were obtained for each of n =\n",
            "442 diabetes patients, as well as the response of interest, a\n",
            "quantitative measure of disease progression one year after baseline.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "  :Number of Instances: 442\n",
            "\n",
            "  :Number of Attributes: First 10 columns are numeric predictive values\n",
            "\n",
            "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
            "\n",
            "  :Attribute Information:\n",
            "      - Age\n",
            "      - Sex\n",
            "      - Body mass index\n",
            "      - Average blood pressure\n",
            "      - S1\n",
            "      - S2\n",
            "      - S3\n",
            "      - S4\n",
            "      - S5\n",
            "      - S6\n",
            "\n",
            "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
            "\n",
            "Source URL:\n",
            "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
            "\n",
            "For more information see:\n",
            "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
            "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
            "(397, 10)\n",
            "(45, 10)\n",
            "(397,)\n",
            "(45,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeaJ3du4TwtB"
      },
      "source": [
        "## Define functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcGdW2ivTwtC"
      },
      "source": [
        "# Define helper functions\n",
        "\n",
        "def evaluate(model, x_test, y_test):\n",
        "    test_loss, test_acc = model.evaluate(x=x_test, y=y_test, verbose=0)\n",
        "    print('accuracy = {acc:0.2f}%, Loss = {loss:0.2f}'.format(acc = test_acc * 100, loss = test_loss))\n",
        "    \n",
        "def get_new_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation = 'relu', input_shape = (x_train.shape[1],)),\n",
        "        Dense(128, activation = 'relu'),\n",
        "        Dense(128, activation = 'relu'),\n",
        "        Dense(128, activation = 'relu'),\n",
        "        Dense(128, activation = 'relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='mse',\n",
        "                  metrics=['mae'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgNDj-BtTwtH"
      },
      "source": [
        "## Custom Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odqkE6xYTwtI"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class TrainingCallback(Callback):\n",
        "    def on_train_begin(self, logs = None):\n",
        "        print('Starting Training...')\n",
        "    def on_epoch_begin(self, epoch, logs = None):\n",
        "        print('Starting Epoch:', epoch)\n",
        "    def on_train_batch_begin(self, batch, logs = None):\n",
        "        print('Training: Staring Batch', batch)\n",
        "    def on_train_batch_end(self, batch, logs = None):\n",
        "        print('Training: Finished Batch', batch)\n",
        "    def on_epoch_end(self, epoch, logs = None):\n",
        "        print('Finished Epoch:', epoch)\n",
        "    def on_train_end(self, logs = None):\n",
        "        print('Finished Training...')\n",
        "        \n",
        "class TestingCallback(Callback):\n",
        "    def on_test_begin(self, logs = None):\n",
        "        print('Starting Testing')\n",
        "    def on_test_batch_begin(self, batch, logs = None):\n",
        "        print('Testing: Starting Batch:', batch)\n",
        "    def on_test_batch_end(self, batch, logs = None):\n",
        "        print('Testing: Finished Batch:', batch)\n",
        "    def on_test_end(self, logs = None):\n",
        "        print('Finished Testing')\n",
        "        \n",
        "class PredictingCallback(Callback):\n",
        "    def on_predict_begin(self, logs = None):\n",
        "        print('Starting Predicting')\n",
        "    def on_predict_batch_begin(self, batch, logs = None):\n",
        "        print('Predicting: Starting Batch:', batch)\n",
        "    def on_predict_batch_end(self, batch, logs = None):\n",
        "        print('Predicting: Finished Batch:', batch)\n",
        "    def on_predict_end(self, logs = None):\n",
        "        print('Finished Predicting')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WyubUfBTwtO"
      },
      "source": [
        "## Train model with callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "C0n0uRm3TwtP",
        "outputId": "112341e6-b4e7-4f8a-9b81-d962a0295a26"
      },
      "source": [
        "# callback objects\n",
        "traincb = TrainingCallback()\n",
        "testcb = TestingCallback()\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "                validation_data = (x_test, y_test),\n",
        "                epochs = 3,\n",
        "                verbose = 0,\n",
        "                callbacks = [traincb, testcb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Training...\n",
            "Starting Epoch: 0\n",
            "Training: Staring Batch 0\n",
            "Training: Finished Batch 0\n",
            "Training: Staring Batch 1\n",
            "Training: Finished Batch 1\n",
            "Training: Staring Batch 2\n",
            "Training: Finished Batch 2\n",
            "Training: Staring Batch 3\n",
            "Training: Finished Batch 3\n",
            "Training: Staring Batch 4\n",
            "Training: Finished Batch 4\n",
            "Training: Staring Batch 5\n",
            "Training: Finished Batch 5\n",
            "Training: Staring Batch 6\n",
            "Training: Finished Batch 6\n",
            "Training: Staring Batch 7\n",
            "Training: Finished Batch 7\n",
            "Training: Staring Batch 8\n",
            "Training: Finished Batch 8\n",
            "Training: Staring Batch 9\n",
            "Training: Finished Batch 9\n",
            "Training: Staring Batch 10\n",
            "Training: Finished Batch 10\n",
            "Training: Staring Batch 11\n",
            "Training: Finished Batch 11\n",
            "Training: Staring Batch 12\n",
            "Training: Finished Batch 12\n",
            "Starting Testing\n",
            "Testing: Starting Batch: 0\n",
            "Testing: Finished Batch: 0\n",
            "Testing: Starting Batch: 1\n",
            "Testing: Finished Batch: 1\n",
            "Finished Testing\n",
            "Finished Epoch: 0\n",
            "Starting Epoch: 1\n",
            "Training: Staring Batch 0\n",
            "Training: Finished Batch 0\n",
            "Training: Staring Batch 1\n",
            "Training: Finished Batch 1\n",
            "Training: Staring Batch 2\n",
            "Training: Finished Batch 2\n",
            "Training: Staring Batch 3\n",
            "Training: Finished Batch 3\n",
            "Training: Staring Batch 4\n",
            "Training: Finished Batch 4\n",
            "Training: Staring Batch 5\n",
            "Training: Finished Batch 5\n",
            "Training: Staring Batch 6\n",
            "Training: Finished Batch 6\n",
            "Training: Staring Batch 7\n",
            "Training: Finished Batch 7\n",
            "Training: Staring Batch 8\n",
            "Training: Finished Batch 8\n",
            "Training: Staring Batch 9\n",
            "Training: Finished Batch 9\n",
            "Training: Staring Batch 10\n",
            "Training: Finished Batch 10\n",
            "Training: Staring Batch 11\n",
            "Training: Finished Batch 11\n",
            "Training: Staring Batch 12\n",
            "Training: Finished Batch 12\n",
            "Starting Testing\n",
            "Testing: Starting Batch: 0\n",
            "Testing: Finished Batch: 0\n",
            "Testing: Starting Batch: 1\n",
            "Testing: Finished Batch: 1\n",
            "Finished Testing\n",
            "Finished Epoch: 1\n",
            "Starting Epoch: 2\n",
            "Training: Staring Batch 0\n",
            "Training: Finished Batch 0\n",
            "Training: Staring Batch 1\n",
            "Training: Finished Batch 1\n",
            "Training: Staring Batch 2\n",
            "Training: Finished Batch 2\n",
            "Training: Staring Batch 3\n",
            "Training: Finished Batch 3\n",
            "Training: Staring Batch 4\n",
            "Training: Finished Batch 4\n",
            "Training: Staring Batch 5\n",
            "Training: Finished Batch 5\n",
            "Training: Staring Batch 6\n",
            "Training: Finished Batch 6\n",
            "Training: Staring Batch 7\n",
            "Training: Finished Batch 7\n",
            "Training: Staring Batch 8\n",
            "Training: Finished Batch 8\n",
            "Training: Staring Batch 9\n",
            "Training: Finished Batch 9\n",
            "Training: Staring Batch 10\n",
            "Training: Finished Batch 10\n",
            "Training: Staring Batch 11\n",
            "Training: Finished Batch 11\n",
            "Training: Staring Batch 12\n",
            "Training: Finished Batch 12\n",
            "Starting Testing\n",
            "Testing: Starting Batch: 0\n",
            "Testing: Finished Batch: 0\n",
            "Testing: Starting Batch: 1\n",
            "Testing: Finished Batch: 1\n",
            "Finished Testing\n",
            "Finished Epoch: 2\n",
            "Finished Training...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}