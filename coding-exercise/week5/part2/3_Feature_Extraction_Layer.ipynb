{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Feature Extraction Layer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aye-Nyein-Thaw/TensorFlow-Beginner/blob/main/coding-exercise/week%205/part2/3_Feature_Extraction_Layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0USbdEo3_Xu"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCysLQxS3_Xz"
      },
      "source": [
        "## Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnObj9i_3_X0"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(6, name = 'Dense_0', input_shape = (4,)),\n",
        "    Dense(4, name = 'Dense_1'),\n",
        "    Dense(3, name = 'output_layer')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AThdTkMt3_X6"
      },
      "source": [
        "## Freeze second layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adfzTdhE3_X7"
      },
      "source": [
        "model.layers[1].trainable = False\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVT4mS0x3_YA"
      },
      "source": [
        "## Load TensorFlow Hub Feature Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBG0d6qW3_YB"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "handle_base = \"mobilenet_v2\"\n",
        "pixels = 224\n",
        "output_features = 1280\n",
        "\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "\n",
        "# The output of the module is a batch of feature vectors. \n",
        "# For each input image, the feature vector has size num_features = 1280"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0Fcos0A3_YH"
      },
      "source": [
        "## Feature extraction layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obulYIIL3_YI"
      },
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE, input_shape=IMAGE_SIZE + (3,))\n",
        "\n",
        "# To fine-tune this feature_extractor layer\n",
        "# set feature_extractor.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge90REDqEsW6"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCxrKDY73_YM"
      },
      "source": [
        "model = Sequential([\n",
        "            feature_extractor,\n",
        "            Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNXoRTlk74V-"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ewYBiMQ7yao"
      },
      "source": [
        "splits = ['train[:80%]', 'train[80%:90%]', 'train[90%:]']\n",
        "\n",
        "splits, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True, split=splits)\n",
        "\n",
        "(train_examples, validation_examples, test_examples) = splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaW6OkXk3_YX"
      },
      "source": [
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes\n",
        "\n",
        "class_names = ['cat', 'dog']\n",
        "\n",
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
        "    return  image, label\n",
        "    \n",
        "BATCH_SIZE =  32\n",
        "\n",
        "train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = test_examples.map(format_image).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgFjTwNL_HPF"
      },
      "source": [
        "## Compile and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XangT2OA3_Yb"
      },
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=3,\n",
        "                    validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJs62tXJ_PxM"
      },
      "source": [
        "## Test with our own image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaRndbtH3_Yg"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "filepath = # path to your image file, example - 'image/cat.jpg'\n",
        "test_img = load_img(filepath , target_size = (pixels, pixels))\n",
        "\n",
        "# convert image to array\n",
        "img_arr = img_to_array(test_img)\n",
        "\n",
        "# normalize\n",
        "img_arr = img_arr / 255.0\n",
        "\n",
        "# expand_dimensions\n",
        "img_arr = img_arr[np.newaxis, ...]\n",
        "results = model.predict(img_arr)\n",
        "\n",
        "prediction = class_names[np.argmax(results)]\n",
        "print(prediction)\n",
        "\n",
        "display(test_img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
